[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/bruin/HW0.html",
    "href": "posts/bruin/HW0.html",
    "title": "Contructing data visualization of the Palmer Penguin data set",
    "section": "",
    "text": "In this blog, I will be explaining how to construct a data visualization of the Palmer Penguins data set."
  },
  {
    "objectID": "posts/bruin/HW0.html#breakdown-of-the-code",
    "href": "posts/bruin/HW0.html#breakdown-of-the-code",
    "title": "Contructing data visualization of the Palmer Penguin data set",
    "section": "Breakdown of the Code",
    "text": "Breakdown of the Code\nTo generate the interactive plot, we will be using the following code to generate the plot. fig = px.scatter(data_frame = dataset, x = “column name 1”, y = “column name 2”, title = “title of plot”, color = “column name 3”, hover_data = [“other columns to display”], width = num, height = num, opacity = num )\nThe arguments used is:  - data_frame = dataset we are using for this plot - x = a specific column from the data set that will be used on the x-axis - y = a sepcific column from the data set tht will be used on the y-axis - title = main title of the plot - color = the color of the points (can be used to seperate different categories i.e. species of penguins) - hover_data = other column information that you would like to display when user hovers over a specific point (note: the columns used for x, y, and color will already be shown when the user hovers over a specific point) - width = the width of the plot - height = the height of the plot - opacity = allows the point on the plot to be sheer\nWe will now be replacing our data set with the respective column names into the code.\n\nfig = px.scatter(data_frame = penguins,\n                 x = \"Body Mass (g)\",\n                 y = \"Flipper Length (mm)\",\n                 title = \"Body Mass and Flipper Length in Penguin Species\",\n                 color = \"Species\",\n                 hover_data = [\"Individual ID\"],\n                 width = 500,\n                 height = 300,\n                 opacity = 0.5\n                )\n\nfig.update_layout(margin={\"r\":0, \"t\":30, \"l\":0, \"b\":0})\nfig.show()\n\n                                                \n\n\nIf we hover our cursor over the points in the plot, we can see information about the specific point. For this particular example, it is able to show you the type of species, the body mass/flipper length for this particular penguin, and the penguin’s ID number."
  },
  {
    "objectID": "posts/bruin/HW0.html#analysis-of-plot",
    "href": "posts/bruin/HW0.html#analysis-of-plot",
    "title": "Contructing data visualization of the Palmer Penguin data set",
    "section": "Analysis of Plot",
    "text": "Analysis of Plot\nFrom the outputted plot, we can see that Gentoo Penguins have a bigger body mass and longer flippers compared to Adelie and Chinstrap penguins. In addition, we can see the Adelie and Chinstrap penguins have similar body mass and Flipper length. Therefore, there does seem to be a correlation between flipper length and body mass of the penguins. For penguins with bigger body mass, they seem to have longer flippers, while smaller body mass penguins have shorter flippers. It is possible that the bigger penguins will need to have bigger flippers for balance and support!"
  },
  {
    "objectID": "posts/bruin/HW0.html#additional-style-choices",
    "href": "posts/bruin/HW0.html#additional-style-choices",
    "title": "Contructing data visualization of the Palmer Penguin data set",
    "section": "Additional Style Choices",
    "text": "Additional Style Choices\nIn addition, we added a following line of code: fig.update_layout(margin={“r”:0, “t”:0, “l”:0, “b”:0})\nThis allows the plot to look a lot neater when generated. Let me show you the difference of using it and not using it.\n\nfig = px.scatter(data_frame = penguins,\n                 x = \"Body Mass (g)\",\n                 y = \"Flipper Length (mm)\",\n                 title = \"Body Mass and Flipper Length in Penguin Species\",\n                 color = \"Species\",\n                 hover_data = [\"Individual ID\"],\n                 width = 500,\n                 height = 300,\n                 opacity = 0.5\n                )\n\n# fig.update_layout(margin={\"r\":0, \"t\":0, \"l\":0, \"b\":0})\nfig.show()\n\n                                                \n\n\nAbove is what it looks like when we commented out the line of code. The plot looks squashed and not as clear compared to when we adjusted the layout of the plot. There are still a lot of other arguments that you can add to the plot to customize it. More information can be found on this website: https://plotly.com"
  },
  {
    "objectID": "posts/bruin/HW1.html",
    "href": "posts/bruin/HW1.html",
    "title": "SQL Tutorial on Climate",
    "section": "",
    "text": "In this blog, I will be explaining how to construct a database using the Temp, stations, and country datasets."
  },
  {
    "objectID": "posts/bruin/HW1.html#interactive-box-plot",
    "href": "posts/bruin/HW1.html#interactive-box-plot",
    "title": "SQL Tutorial on Climate",
    "section": "Interactive Box Plot",
    "text": "Interactive Box Plot\nWe will now create an interactive box plot for the new pandas dataframe we have created. Again, to connect to the database and create the pandas dataframe, we use a similar method as the previous example. We want to create a function that will allow users to easily change parameters to look for different information in the databse and generate a plot. For this specific example, we want to find the temperature changes in UCLA and USC through the months.  To create the box plot, we will use the following code: fig = px.box(df, x = “x-values”, y = “y-values”, color = “specific column”, width = m, height = n, kwargs) - df: dataframe used to create the plot - x: column used for the x-axis - y: column used for the y-axis - color: color of the box plots - kwargs: additional parameters passed through by the user\n\ndef station_temp_plot(db_file, station_one, station_two, **kwargs) :\n    \"\"\"\n    Creating an interactive box plot that identifies the change in temperature between two stations through the months\n    Function will: \n    1. Use station_climate_comparison_database to create a dataframe with all the information needed\n    2. Creating an interactive box plot\n    \"\"\"\n    # inputting parameters passed through station_temp_plot into station_climate_comparison_database\n    df = station_climate_comparison_database(db_file, station_one, station_two) \n    \n    # creating a interactive box plot (more information regarding arguments above)\n    fig = px.box(df,\n             x = \"NAME\",\n             y = \"Temp\",\n             color = \"Month\",\n             width = 600,\n             height = 300,\n            **kwargs)\n\n    # reduce whitespace\n    fig.update_layout(margin={\"r\":0,\"t\":30,\"l\":0,\"b\":10})\n    return fig\n\nNow that we have finished creating our function, we can run our code!\n\nfig = station_temp_plot(\"temps.db\", station_one = \"U_C_L_A\", station_two = \"LOS_ANGELES_DWTN_USC_CAMPUS\",title=\"Temperature Changes Through the Years at UCLA and USC\")\nfig.show()\n\n\n\n\nThrough this plot, we can see the changes in temperatures throughout the year at UCLA and USC. It is clear that it is colder during the in October, November, December, and Janurary while it gets very hot in July for both USC and UCLA. We can see that the trends are typically what we experience in LA. In addition, when we hover over the box plots, we can see information regaring the maximum, median, minimum etc of a specific month."
  },
  {
    "objectID": "posts/bruin/HW1.html#interactive-scatter-plot",
    "href": "posts/bruin/HW1.html#interactive-scatter-plot",
    "title": "SQL Tutorial on Climate",
    "section": "Interactive Scatter Plot",
    "text": "Interactive Scatter Plot\nNow we will be creating an interactive scatter plot! We will again be using the the same code as above to generate our pandas dataframe. In this function (temp_comparison_plot), we want to look at the changes in temperature through the years at UCLA and USC by the seasons. To do so, we will first like to perform some data cleaning. As observed before, our variable Month consisted of 1 to 12, which represents January to December. Since we will like to perform analysis by season, we want to change the months to their respective season. To do so, we will look through the Month column using the .loc function and changing the numbers to the correct season. Now we can generate our plot!\nWe will be using the following code to generate the scatter plot: fig = px.scatter(data_frame = df, x = “Year”, y = “Temp”, color = “Temp”, hover_data = [“LATITUDE”, “LONGITUDE”], size_max = 8, width = 500, height = 300, opacity = 0.5, facet_col = “Month”, facet_row = “NAME”, **kwargs) - data_frame: dataframe used to create the plot - x: column for our x-axis - y: column for our y-axis - color: column corresponding to the color of the points - hover_data: adding more information for the user to see when they hover over a specific point on the plot - facet_col: splitting the plots columnwise using a specific column from the dataframe - facet_row: splitting the plots rowwise using a specific column from the dataframe\n\ndef temp_comparison_plot(db_file, station_one, station_two, **kwargs) :\n    \"\"\"\n    Creating an interactive scatter plot to look at the changes in temperature through the years at two stations by seasons\n    Function will:\n    1. Use station_climate_comparison_database to create a dataframe that contains all the information needed\n    2. Change the specific months into its corresponding season\n    3. Create the interactive scatter plot\n    \"\"\"\n    # using parameters from temp_comparison_plot into station_climate_comparison_database\n    df = station_climate_comparison_database(db_file, station_one, station_two)\n    \n    # replacing the month's to the season they belong in\n    df.loc[(df['Month']==1) | (df['Month']==2) | (df['Month']==12), 'Month'] = \"Winter\" \n    df.loc[(df['Month']==3) | (df['Month']==4) | (df['Month']==5), 'Month'] = \"Spring\"\n    df.loc[(la['Month']==6) | (df['Month']==7) | (df['Month']==8), 'Month'] = \"Summer\"\n    df.loc[(la['Month']==9) | (df['Month']==10) | (df['Month']==11), 'Month'] = \"Fall\" \n\n    # creating an interactive scatter plot (more information regarding arguments above)\n    fig = px.scatter(data_frame = df,\n                 x = \"Year\",\n                 y = \"Temp\",\n                 color = \"Temp\",\n                 hover_data = [\"LATITUDE\", \"LONGITUDE\"],\n                 size_max = 8,\n                 width = 500,\n                 height = 300,\n                 opacity = 0.5,\n                 facet_col = \"Month\",\n                 facet_row = \"NAME\",\n                 **kwargs)\n\n    #reduce whitespace\n    fig.update_layout(margin={\"r\":0, \"t\":80, \"l\":0, \"b\":0})\n    return fig\n\nNow that we have finished creating our function, lets run it!\n\nfig = temp_comparison_plot(\"temps.db\", station_one = \"U_C_L_A\", station_two = \"LOS_ANGELES_DWTN_USC_CAMPUS\",title=\"Temperature Trends Through the Years by Season &lt;br&gt;in UCLA and USC\")\nfig.show()\n\n\n\n\nFrom the output, we can see the changes in temperature throughout the years. We see that all seasons experienced an increase in temperature from the earliest 1901 to 2021. In addition, UCLA and USC seem to follow the same trends."
  },
  {
    "objectID": "posts/bruin/index.html",
    "href": "posts/bruin/index.html",
    "title": "Web Scrapping TMDB",
    "section": "",
    "text": "In the blog, we will be learning how to web scrape through TMDB and create a csv file using the library scrapy."
  },
  {
    "objectID": "posts/bruin/index.html#parse-function",
    "href": "posts/bruin/index.html#parse-function",
    "title": "Web Scrapping TMDB",
    "section": "parse Function",
    "text": "parse Function\nInside our class, we will define another function called parse. This will bring us to the next page that contains the information on the Full Cast and Members.\n\ndef parse(self, response):\n    \"\"\"\n    Parsing through the initial website to get to the cast webpage\n    \"\"\"\n    # getting to the cast page\n    yield scrapy.Request(f\"{response.url}/cast\", \n                         callback = self.parse_full_credits)\n\nIn parse, you can see that we set the first parameter of scrapy.Request to f”{response.url}/cast”. This will take the url that we have selected in the init function, and add on /cast to get to the page with all the cast information."
  },
  {
    "objectID": "posts/bruin/index.html#parse_full_credits-function",
    "href": "posts/bruin/index.html#parse_full_credits-function",
    "title": "Web Scrapping TMDB",
    "section": "parse_full_credits Function",
    "text": "parse_full_credits Function\nFrom the cast information webpage, we will like to go to each individual actor’s webpage. To do so, we will define another function inside the class called parse_full_credits. What this function will do is go through each actor on the website and call the function parse_actor_page.\n\ndef parse_full_credits(self, response):\n    \"\"\"\n    At the cast webpage, this function will look through all the crew members and \n    get link to their own personal webpage \n    \"\"\"\n    # getting the information from the full cast and members\n    for info in response.css(\"ol.people.credits\")[0].css(\"li\") :\n        # getting the links to the individual actors\n        actor = info.css('a::attr(href)').get() \n        yield scrapy.Request(f\"https://www.themoviedb.org{actor}\", \n                             callback = self.parse_actor_page)\n\nIn parse_full_credits, to get to each individual actor’s page, we will use the following command: response.css(“ol.people.credits”)[0].css(“li”).  How do we know we will need to use this command? We will inspect the webpage.  In the webpage, when we hover over a line, we can see the corresponding section highlighted on the website. We will follow all the subcategories until we find the link to an cast member’s webpage.  To get to that section, we will use response.css(“ol.people.credits”)[0].css(“li”). We will put this under a for loop, which will allow us to parse through each individual actor under Cast.  After getting to a single actor, we will use ‘a::attr(href)’ to get the link to the actor’s page. We will then add on the link to https://www.themoviedb.org, by using the following code: f”https://www.themoviedb.org{actor}“. This will send the link to the next function to be parsed."
  },
  {
    "objectID": "posts/bruin/index.html#parse_actor_page-function",
    "href": "posts/bruin/index.html#parse_actor_page-function",
    "title": "Web Scrapping TMDB",
    "section": "parse_actor_page Function",
    "text": "parse_actor_page Function\nWe will now define another function inside the class called parse_actor_page. This will scrape through a specific actor’s page and find all the movies and tv shows the actor had an Acting role in.\n\ndef parse_actor_page(self, response):\n    \"\"\"\n    This function will start at the actor's webpage.\n    It will then take all the movies and TV shows this actor had an Acting role in \n    and insert it into a dictionary.\n    \"\"\"\n    # some actor acting informations are not aligned, therefore we will need \n    # to take that into account and use an if statement to find the correct header\n    header_pos = 0\n        \n    if response.css('h3.zero:contains(\"Acting\")') :\n        header_pos = 0\n    elif response.css('h3.one:contains(\"Acting\")') :\n        header_pos = 1\n    elif response.css('h3.two:contains(\"Acting\")'):\n        header_pos = 2\n        \n    actor_acting = response.css(\"table.card.credits\")[header_pos]\n        \n    for work in actor_acting.css(\"a.tooltip bdi::text\").getall():\n        yield {\"actor\" : response.css(\"h2.title a::text\").get(), \n               \"movie_or_TV_name\" : work}\n\nAgain, we will look through inspect to see exactly where the information we need is located. We need to be very careful in this section, as some cast webpages are out of order.  Specifically, when we look at David Holmes webpage, we see that Acting is not displayed first. Instead, Crew is displayed first on his page. Therefore, to figure out where the Acting section is for each actor, we will use an if statement.  Under inspect, we see that h3 contains all the information on the movies and tv shows that actors has been in and whether they were in Acting, Crew, or Production. Therefore, to find the specific h3 that has the information on the movies and tv shows an actor had an Acting role in, we will use the following command: ‘h3.zero:contains(“Acting”)’, ‘h3.one:contains(“Acting”)’ or ‘h3.two:contains(“Acting”)’. This will look through the text in h3 and see if Acting is in the line. If it is, we will then set header_pos.  Next, we will use the command response.css(“table.card.credits”)[header_pos] which will use the position of the header to get to the information on the movies and tv shows the actor has been in.  To get the movie and tv show name, we will use actor_acting.css(“a.tooltip bdi::text”).getall(). This will get the names of all the movies and tv show’s the actor has been in.  Now, we want to add the information into a dictionary. We will for loop through the result and add the titles to the corresponding actor.\nNow that we have completed our code, we can run our code by using the following terminal command:  scrapy crawl tmdb_spider -o movies.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone  If you would like to parse through another movie, simply replace the subdir to another movie’s link.  If you run into any issues, you will have to use an USER_AGENT to make the website not think you are a bot. You can add this command to the terminal command: -s USER_AGENT=’Mozilla/5.0 (Macintosh; Intel Mac OS X 11_5_2) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.2 Safari/605.1.15\nAfterwards, you should have a file generated that has all of the information you need."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "Web Scrapping TMDB\n\n\n\n\n\n\nWeek 5\n\n\nHW2\n\n\n\n\n\n\n\n\n\nFeb 12, 2024\n\n\nShaina Wang\n\n\n\n\n\n\n\n\n\n\n\n\nSQL Tutorial on Climate\n\n\n\n\n\n\nWeek 3\n\n\nHW1\n\n\n\n\n\n\n\n\n\nJan 29, 2024\n\n\nShaina Wang\n\n\n\n\n\n\n\n\n\n\n\n\nContructing data visualization of the Palmer Penguin data set\n\n\n\n\n\n\nWeek 1\n\n\nHW0\n\n\n\n\n\n\n\n\n\nJan 20, 2024\n\n\nShaina Wang\n\n\n\n\n\n\nNo matching items"
  }
]